{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mpd\n",
    "import pylab as plt\n",
    "import datetime\n",
    "#\n",
    "import re\n",
    "#\n",
    "import json\n",
    "import netCDF4\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NML(object):\n",
    "    def nml_to_json(self, nml_in=None, json_out=None):\n",
    "        '''\n",
    "        # convert nml to dict; save dict as class member; if json_out is not None,\n",
    "        # export json to json_out\n",
    "        #\n",
    "        # @nml_in: filenname of input nml\n",
    "        # @json_out: filename of output json file.\n",
    "        #. \n",
    "        '''\n",
    "        #\n",
    "        if nml_in is None:\n",
    "            nml_in = self.nml\n",
    "        #\n",
    "        nml_dict = {}\n",
    "        group_name = ''\n",
    "        #k_group = 0\n",
    "        #\n",
    "        values_out = {}\n",
    "        ky = ''\n",
    "        \n",
    "        with open(nml_in) as fin:\n",
    "            for rw in fin:\n",
    "                rw = rw.strip()\n",
    "                #\n",
    "                # TODO: maye we should retain comments? if so, we'll need to switch the nested\n",
    "                #. structure to a list (-like), instead of a dict., to allow for multiple commented-out\n",
    "                #  entries.\n",
    "                #\n",
    "                # for a mid-line comment:\n",
    "                rw = rw.split('!')[0]\n",
    "                #\n",
    "                if len(rw)==0 or rw[0] in ['!', '/', '\\n']:\n",
    "                    continue\n",
    "                #\n",
    "                if rw[0]=='&':\n",
    "                    # new group:\n",
    "                    if not group_name == '':\n",
    "                        nml_dict[group_name]=values_out\n",
    "                    #\n",
    "                    group_name = rw[1:].strip()\n",
    "                    values_out = {}\n",
    "                    #if not group_name in nml_dict.keys():\n",
    "                    #    nml_dict[group_name]={}\n",
    "                    continue\n",
    "                    #\n",
    "                \n",
    "                #\n",
    "                #print('** ', rw)\n",
    "                #\n",
    "                # TODO: this logic is almost right, and will probably work most of the time, but\n",
    "                #. it might be better to be more robust about allowing multi-line entries. Note\n",
    "                #. this will not work properly for a multi-entry line that end in a multi-line entry.\n",
    "                ky_vl = rw.split('=')\n",
    "                if len(ky_vl) == 1:\n",
    "                    #print('*** debug: ', val, ky_vl)\n",
    "                    val = val + ky_vl[0]\n",
    "                    continue\n",
    "                elif len(ky_vl) == 2:\n",
    "                    if not ky=='':\n",
    "                        values_out[ky]=val.strip()\n",
    "                    ky,val = [s.strip() for s in ky_vl]\n",
    "                elif len(ky_vl) > 2:\n",
    "                    # there are multiple entries, presumably separated by commas?? so\n",
    "                    # key=val,key=val,key=val...\n",
    "                    #print('** DEBUG: ', [s.strip() for s in re.split('=|,', rw) if not s.strip()==''])\n",
    "                    values_out.update(dict(numpy.reshape([s.strip()\n",
    "                                        for s in re.split('=|,', rw) if not s.strip()==''], (-1,2))))\n",
    "                \n",
    "            #\n",
    "        #\n",
    "        self.nml_dict=nml_dict\n",
    "        #\n",
    "        if not json_out is None:\n",
    "            with open(json_out, 'w') as fout:\n",
    "                json.dump(nml_dict, fout)\n",
    "            #\n",
    "        #\n",
    "        return nml_dict\n",
    "    def nml_to_json_depricated(self, nml_in=None, json_out=None):\n",
    "        '''\n",
    "        # convert nml to dict; save dict as class member; if json_out is not None,\n",
    "        # export json to json_out\n",
    "        #\n",
    "        # @nml_in: filenname of input nml\n",
    "        # @json_out: filename of output json file.\n",
    "        #. \n",
    "        '''\n",
    "        #\n",
    "        if nml_in is None:\n",
    "            nml_in = self.nml\n",
    "        #\n",
    "        nml_dict = {}\n",
    "        group_name = ''\n",
    "        #k_group = 0\n",
    "        #\n",
    "        value_out = ''\n",
    "        ky = ''\n",
    "        with open(nml_in) as fin:\n",
    "            for rw in fin:\n",
    "                rw = rw.strip().split()\n",
    "                #\n",
    "                if len(rw)==0 or rw[0] in ['/', '\\n', '!']:\n",
    "                    continue\n",
    "                #\n",
    "                if rw[0]=='&':\n",
    "                    # new group:\n",
    "                    #group_name = rw[1:].replace('\\n', '')\n",
    "                    group_name = rw[1:].strip()\n",
    "                    if not group_name in nml_dict.keys():\n",
    "                        nml_dict[group_name]={}\n",
    "                    continue\n",
    "                    #\n",
    "                #\n",
    "                #print('** ', rw)\n",
    "                if '=' in rw:\n",
    "                    if ky != '':\n",
    "                        nml_dict[group_name][ky] = value_out\n",
    "                        #\n",
    "                    ky,value_out =(s.strip() for s in rw.split('='))\n",
    "                    #\n",
    "                else:\n",
    "                    value_out = value_out + rw.strip()\n",
    "            #\n",
    "        #\n",
    "        self.nml_dict=nml_dict\n",
    "        #\n",
    "        if not json_out is None:\n",
    "            with open(json_out, 'w') as fout:\n",
    "                json.dump(nml_dict, fout)\n",
    "            #\n",
    "        #\n",
    "        return nml_dict\n",
    "    #\n",
    "    def json_to_nml(self, json_in=None, nml_out='input.nml', indent=None):\n",
    "        '''\n",
    "        # convert json or dict to an nml. export to nml_out.\n",
    "        '''\n",
    "        #\n",
    "        if json_in is None:\n",
    "            json_in = self.nml_dict\n",
    "        #\n",
    "        if indent is None:\n",
    "            indent=''\n",
    "            for k in range(4):\n",
    "                indent = indent + chr(32)\n",
    "            #\n",
    "        #\n",
    "        if isinstance(json_in, str):\n",
    "            with open(json_in, 'r') as fin:\n",
    "                json_in = json.load(fin)\n",
    "            #\n",
    "        #\n",
    "        with open(nml_out) as fout:\n",
    "            for group,entries in json_in.items():\n",
    "                fout.write('&{}\\n'.format(group))\n",
    "                #\n",
    "                for entry,val in entries.items():\n",
    "                    fout.write('{}{}={}'.format(indent, entry, val ))\n",
    "                #\n",
    "            #\n",
    "            \n",
    "                    \n",
    "\n",
    "class NML_from_nml(NML):\n",
    "    def __init__(self, input_nml):\n",
    "        #\n",
    "        super(NML_from_nml,self).__init__()\n",
    "        #\n",
    "        with open(input_nml) as fin:\n",
    "            self.nml = fin.read()\n",
    "        #\n",
    "        self.nml_json = self.nml_to_json(input_nml)\n",
    "        \n",
    "    #\n",
    "class NML_from_json(NML):\n",
    "    def __init__(self, input_json, nml_out):\n",
    "        #\n",
    "        super(NML_from_json,self).__init__()\n",
    "        #\n",
    "        with open(input_json) as fin:\n",
    "            self.nml_json = json.load(fin)\n",
    "        #\n",
    "        self.nml = self.json_to_nml(self.nml_json, nml_out)\n",
    "        \n",
    "    #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "JJ = NML_from_nml('input_yoder_v101.nml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** coupler_nml:{'force_donner_moist_conserv': '.false.,', 'months': '1,', 'days': '0,', 'current_date': '1979,1,1,0,0,0,', 'calendar': \"'julian'\", 'dt_atmos': '1800,', 'dt_cpld': '7200,', 'use_lag_fluxes': '.true.', 'concurrent': '.false.', 'do_ocean': '.false.', 'ocean_npes': '0', 'atmos_npes': '48', 'atmos_nthreads': '1', 'use_hyper_thread': '.false.'}\n",
      "\n",
      "*** coupler_nml:{'force_donner_moist_conserv': '.false.,', 'months': '1,', 'days': '0,', 'current_date': '1979,1,1,0,0,0,', 'calendar': \"'julian'\", 'dt_atmos': '1800,', 'dt_cpld': '7200,', 'use_lag_fluxes': '.true.', 'concurrent': '.false.', 'do_ocean': '.false.', 'ocean_npes': '0', 'atmos_npes': '48', 'atmos_nthreads': '1', 'use_hyper_thread': '.false.'}\n",
      "\n",
      "*** vegn_data_nml:{'nom_ratio': '0.7', 'vegn_to_use': \"'uniform'\", 'K1': '10,', 'K2': '0.1,', 'fsc_liv': '0.9,', 'fsc_wood': '0.45,', 'c1(4)': '0.3', 'c2(4)': '0.3', 'Vmax': '2.0E-5, 2.0E-5, 2.0E-5, 2.0E-5, 1.50E-5,', 'm_cond': '4., 9., 9., 7., 7.,', 'alpha_phot': '0.05, 0.06, 0.06, 0.06, 0.06,', 'gamma_resp': '0.03, 0.02, 0.02, 0.02, 0.02,', 'tc_crit(0:2)': '3*273.16', 'fact_crit_phen(0:4)': '0., 0., 0., 0., 0.', 'fact_crit_fire(0:4)': '0., 0., 0., 0., 0.', 'cnst_crit_phen(0:4)': '0.30, 0.15, 0.15, 0.30, 0.30', 'cnst_crit_fire(0:4)': '0.15,  0.40, 0.15, 0.15, 0.15', 'wet_leaf_dreg(0:4)': '.3, .3, .3, .3, .3', 'ksi': '0, 0, 0, 0, 0,', 'leaf_refl(0:4,1)': '0.11, 0.11, 0.10, 0.10, 0.10', 'leaf_refl(0:4,2)': '0.58, 0.58, 0.45, 0.45, 0.39,', 'dat_root_zeta(0:4)': '0.35212, 0.17039, 0.28909, 0.25813, 0.17039', 'critical_root_density': '0.0,', 'tau_drip_s': '259200.0', 'cmc_lai(0:4)': '0.02, 0.02, 0.02, 0.02, 0.02', 'csc_lai(0:4)': '0.30, 0.30, 0.30, 0.30, 0.60', 'dat_snow_crit': '4*1.e7, .1', 't_transp_min': '268.', 'srl(0:1)': '112.0e3, 150.0e3', 'root_perm': '14*5e-7', 'alpha(1,3)': '4', 'leaf_age_tau(2)': '150', 'smoke_fraction': '0.9, 0.9, 0.6, 0.6, 0.6', 'tg_c3_thresh': '1', 'phen_ev1': '0.2', 'phen_ev2': '0.7', 'cmc_eps': '0.01', 'alpha(0:4,6)': '0.0, 0.0, 0.012, 0.012, 0.012'}\n",
      "\n",
      "*** simple_sulfate_nml:{'time_varying_solar_constant': '.true.,', 'gas_conc_filename': \"'gas_conc_3D_am3p9.nc'\", 'gas_conc_time_dependency_type': \"'constant'\", 'cont_volc_source': \"'do_cont_volc'\", 'expl_volc_source': \"'do_expl_volc'\", 'aerocom_emission_filename': \"'so2_0.25_volcanoes.nc'\", 'aircraft_source': \"'do_aircraft',\", 'aircraft_filename': \"'emissions.aircraft.aero.0.5x0.5.1849-2016.nc',\", 'aircraft_emission_name(1)': \"'fuel'\", 'aircraft_time_dependency_type': \"'time_varying'\", 'aircraft_dataset_entry': '1979 1 1 0 0 0', 'so2_aircraft_EI': '0.001', 'anthro_source': \"'do_anthro',\", 'anthro_emission_name(1)': \"'so2ff',\", 'anthro_emission_name(2)': \"'so4ff',\", 'anthro_time_dependency_type': \"'time_varying'\", 'anthro_dataset_entry': '1979 1 1 0 0 0', 'anthro_filename': \"'anthro_so2.1849_2016.nc',\", 'biobur_source': \"'do_biobur',\", 'biobur_emission_name(1)': \"'so2bb',\", 'biobur_emission_name(2)': \"'so4bb',\", 'biobur_time_dependency_type': \"'time_varying'\", 'biobur_dataset_entry': '1979 1 1 0 0 0', 'biobur_filename': \"'anthro_so2.1849_2016.nc',\", 'cloud_chem_solver': '\"f1p\"', 'pH_cloud': '4.5'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for ky,vl in JJ.nml_dict.items():\n",
    "#     print('** {}: {}'.format(ky,vl))\n",
    "\n",
    "\n",
    "for ky in ['coupler_nml','coupler_nml', 'vegn_data_nml', 'simple_sulfate_nml' ]:\n",
    "    print('*** {}:{}\\n'.format(ky, JJ.nml_dict[ky]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,35,35,35,35,35,40,40,40,40,40,45,45,45,45,45,50,50,50,50,50,55,55,55,55,55,60,60,60,60,60,65,65,65,65,65,70,70,70,70,70,75,75,75,75,75,80,80,80,80,82,82,84,84,86,86,88,88,90,91,92,93,94,95,96,97,97,97,97,\n"
     ]
    }
   ],
   "source": [
    "print(JJ.nml_dict['aerosolrad_package_nml']['sulfate_indices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
