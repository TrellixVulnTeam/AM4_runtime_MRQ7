{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mpd\n",
    "import pylab as plt\n",
    "import datetime\n",
    "#\n",
    "import re\n",
    "#\n",
    "import json\n",
    "import netCDF4\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NML(dict):\n",
    "    #\n",
    "    def __init__(self):\n",
    "        self.__dict__.update({ky:vl for ky,vl in locals().items() if not ky in ('self', '__class__')})\n",
    "    \n",
    "    #\n",
    "    def assign(self, ky1, ky2, val):\n",
    "        # a \"safe\" assignment operator. If the keys do not exist, fail and raise an exception.\n",
    "        if ky1 in self.keys() and ky2 in self[ky1].keys():\n",
    "            self[ky1][ky2] = val\n",
    "            #\n",
    "            return True\n",
    "        else:\n",
    "            err_str = '{} not in self[{}].keys()'.format(ky2, ky1)\n",
    "            if not(ky1) in self.keys():\n",
    "                err_str = \"{} not in self.keys()\"\n",
    "            #\n",
    "            raise NameError(err_str)\n",
    "            return False\n",
    "    #\n",
    "    def nml_to_json(self, nml_in=None, json_out=None):\n",
    "        '''\n",
    "        # convert nml to dict; save dict as class member; if json_out is not None,\n",
    "        # export json to json_out\n",
    "        #\n",
    "        # NOTE: The format for .nml does not appear to be very strictly defined. Basically, it is not\n",
    "        #. well defined if key-value pairs are separated by CRLF ('\\n') or comma ',' -- oh, and also commas\n",
    "        #. are allowed (in some cases) withink values. So this might be a work in progress, to be able\n",
    "        #. to generally define k-v pairs. Right now, its success rests a little bit on, \"please, all that\n",
    "        #. is holy, let them not allow this or that...\"\n",
    "        #\n",
    "        # @nml_in: filenname of input nml\n",
    "        # @json_out: filename of output json file.\n",
    "        #. \n",
    "        '''\n",
    "        #\n",
    "        if nml_in is None:\n",
    "            nml_in = self.nml\n",
    "        #\n",
    "        #nml_dict = {}\n",
    "        group_name = ''\n",
    "        #k_group = 0\n",
    "        #\n",
    "        values_out = {}\n",
    "        ky = ''\n",
    "        \n",
    "        with open(nml_in) as fin:\n",
    "            for rw in fin:\n",
    "                rw = rw.strip()\n",
    "                #\n",
    "                # TODO: maye we should retain comments? if so, we'll need to switch the nested\n",
    "                #. structure to a list (-like), instead of a dict., to allow for multiple commented-out\n",
    "                #  entries.\n",
    "                #\n",
    "                # for a mid-line comment:\n",
    "                rw = rw.split('!')[0]\n",
    "                #\n",
    "                if len(rw)==0 or rw[0] in ['!', '\\n']:\n",
    "                    continue\n",
    "                #\n",
    "                if rw[0]=='&':\n",
    "                    # new group:\n",
    "                    if not group_name == '':\n",
    "                        self[group_name] = values_out\n",
    "                        #nml_dict[group_name]=values_out\n",
    "                    #\n",
    "                    group_name = rw[1:].strip()\n",
    "                    values_out = {}\n",
    "                    ky=''\n",
    "                    val=''\n",
    "                    #if not group_name in nml_dict.keys():\n",
    "                    #    nml_dict[group_name]={}\n",
    "                    continue\n",
    "                    #\n",
    "                \n",
    "                #\n",
    "                #print('** ', rw)\n",
    "                #\n",
    "                # TODO: this logic is almost right, and will probably work most of the time, but\n",
    "                #. it might be better to be more robust about allowing multi-line entries. Note\n",
    "                #. this will not work properly for a multi-entry line that end in a multi-line entry.\n",
    "                if rw.startswith('/'):\n",
    "                    values_out[ky]=val.strip()\n",
    "                    continue\n",
    "                #\n",
    "                ky_vl = rw.split('=')\n",
    "                if len(ky_vl) == 1:\n",
    "                    #print('*** debug: ', val, ky_vl)\n",
    "                    val = val + ky_vl[0]\n",
    "                    continue\n",
    "                elif len(ky_vl) == 2:\n",
    "                    if not ky=='':\n",
    "                        values_out[ky]=val.strip()\n",
    "                    ky,val = [s.strip() for s in ky_vl]\n",
    "                elif len(ky_vl) > 2:\n",
    "                    # there are multiple entries, presumably separated by commas?? so\n",
    "                    # key=val,key=val,key=val...\n",
    "                    #print('** DEBUG: ', [s.strip() for s in re.split('=|,', rw) if not s.strip()==''])\n",
    "                    values_out.update(dict(numpy.reshape([s.strip()\n",
    "                                        for s in re.split('=|,', rw) if not s.strip()==''], (-1,2))))\n",
    "                \n",
    "            #\n",
    "        #\n",
    "        #self.nml_dict=nml_dict\n",
    "        #self.update(nml_dict)\n",
    "        #\n",
    "        if not json_out is None:\n",
    "            with open(json_out, 'w') as fout:\n",
    "                #json.dump(nml_dict, fout)\n",
    "                # can we just dump self?\n",
    "                json.dump(self, fout)\n",
    "                #json.dump({ky:vl for ky,vl in self.items()})\n",
    "            #\n",
    "        #\n",
    "        return None\n",
    "        #return nml_dict\n",
    "    #\n",
    "    \n",
    "    #\n",
    "    def json_to_nml(self, nml_out='input.nml', json_in=None, indent=None, file_mode='w'):\n",
    "        '''\n",
    "        # convert json or dict to an nml. export to nml_out.\n",
    "        # TODO: continue to evaluate how lists, tuples, etc. are encoundered and handled. For example,\n",
    "        #  we want output to be like, format = 6,8 , not format = [6,8]. so far, i don't see any \"[]\"\n",
    "        #. characters in .nml files, so we can probably just get rid of them, but it might be smarter\n",
    "        #. to just recognize when we have a list type... or to enforce that all values are saved internally\n",
    "        #  as strings... The latter may become necessary, since there does not appear to be a good standard\n",
    "        #. for comma, space, etc. separating values (or fields).\n",
    "        '''\n",
    "        #\n",
    "        if json_in is None:\n",
    "            json_in = self\n",
    "        #\n",
    "        if indent is None:\n",
    "            indent = 4*chr(32)\n",
    "            #\n",
    "        #\n",
    "        if isinstance(json_in, str):\n",
    "            with open(json_in, 'r') as fin:\n",
    "                json_in = json.load(fin)\n",
    "            #\n",
    "        #\n",
    "        with open(nml_out, file_mode) as fout:\n",
    "            for group,entries in json_in.items():\n",
    "                fout.write('&{}\\n'.format(group))\n",
    "                #\n",
    "                for entry,val in entries.items():\n",
    "                    fout.write('{}{} = {}\\n'.format(indent, entry, val ))\n",
    "                fout.write('/\\n\\n')\n",
    "                \n",
    "                #\n",
    "            #\n",
    "            \n",
    "                    \n",
    "class NML_from_nml(NML):\n",
    "    def __init__(self, input_nml, json_out=None):\n",
    "        #\n",
    "        super(NML_from_nml,self).__init__()\n",
    "        self.__dict__.update({ky:vl for ky,vl in locals().items() if not ky in ('self', '__class__')})\n",
    "        #\n",
    "        # is this useful?\n",
    "        #with open(input_nml) as fin:\n",
    "        #    self.nml = fin.read()\n",
    "        #\n",
    "        self.nml_to_json(input_nml, json_out=json_out)\n",
    "        \n",
    "    #\n",
    "class NML_from_json(NML):\n",
    "    def __init__(self, input_json, nml_out=None):\n",
    "        #\n",
    "        super(NML_from_json,self).__init__()\n",
    "        self.__dict__.update({ky:vl for ky,vl in locals().items() if not ky in ('self', '__class__')})\n",
    "        #\n",
    "        with open(input_json) as fin:\n",
    "            #self.nml_dict = json.load(fin)\n",
    "            self.update(json.load(fin))\n",
    "        #\n",
    "        if not nml_out is None:\n",
    "            self.nml = self.json_to_nml(self.nml_json, nml_out)\n",
    "\n",
    "class AM4_batch_scripter(object):\n",
    "    mpi_execs = {'mpirun':{'exec': 'mpirun', 'ntasks':'--np ', 'cpu_per_task':'-d '},\n",
    "                 'srun':{'exec':'srun', 'ntasks':'--ntasks=', 'cpu_per_task':'--cpus-per-task='}}\n",
    "    #\n",
    "    def __init__(self, work_dir='workdir', input_data_path='', input_data_tar='',\n",
    "                 input_nml='input_template.nml', diag_table_src='', force_copy_input=0, do_tar=0,\n",
    "                 n_tasks=48, n_threads=1):\n",
    "        # parameters? input data file?\n",
    "        #\n",
    "        # not sure what this looks like yet, but... This script/class will be called by a wrapper\n",
    "        #.  script. This process will constitute a step in a larer script (ie, each ~2 hour run in a\n",
    "        #. twohour queue process).\n",
    "        #. script\n",
    "        # 1) review, set up, etc. the working directory\n",
    "        # 2) Are the input data there?\n",
    "        # 3) if not, are the input data availble?\n",
    "        # 4) if not, is the tar available? if not, get it; then open, then copy.\n",
    "        # 5) evaluate the input/output data. Have we achieved our objectives\n",
    "        #.  (which we've not yet defined -- runtime, etc.)? Define restart as necessary \n",
    "        #.   (*** though actually, i guess this will be done by the calling script; this script will\n",
    "        #.    just receive instructions).\n",
    "        # 6) copy diag_table nd create input.nml\n",
    "        # 7) execute MPI command\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    #\n",
    "    def write_batch_script(self):\n",
    "        \n",
    "            \n",
    "    #\n",
    "def get_layouts(n_tasks=24):\n",
    "    '''\n",
    "    # compute possible layouts. Include (some) error checking for valid n_tasks?\n",
    "    '''\n",
    "    # get all integer factor pairs:\n",
    "    return numpy.array(sorted([(k,int(n_tasks/k)) for k in range(1, int(numpy.ceil(n_tasks**.5)))\n",
    "                               if n_tasks%k==0],\n",
    "                                key = lambda rw: numpy.sum(rw)))\n",
    "#\n",
    "def get_io_layouts(layout):\n",
    "    '''\n",
    "    # AM4 io_layouts. the second \"y\" term must be an integer factor of the \"y\" term of the input layout.\n",
    "    #. Don't yet understand the first term, so for now let's limit it to 1.\n",
    "    '''\n",
    "    #\n",
    "    return numpy.array(sorted([(1,int(layout[1]/k)) for k in range(1, int(numpy.ceil(layout[1]**.5)))\n",
    "                               if layout[1]%k==0], \n",
    "                              key=lambda rw:numpy.sum(rw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** coupler_nml:{'months': '1,', 'days': '0,', 'current_date': '1979,1,1,0,0,0,', 'calendar': \"'julian'\", 'dt_atmos': '1800,', 'dt_cpld': '7200,', 'use_lag_fluxes': '.true.', 'concurrent': '.false.', 'do_ocean': '.false.', 'ocean_npes': '0', 'atmos_npes': '48', 'atmos_nthreads': '1', 'use_hyper_thread': '.false.', 'ncores_per_node': '24'}\n",
      "\n",
      "*** coupler_nml:{'months': '1,', 'days': '0,', 'current_date': '1979,1,1,0,0,0,', 'calendar': \"'julian'\", 'dt_atmos': '1800,', 'dt_cpld': '7200,', 'use_lag_fluxes': '.true.', 'concurrent': '.false.', 'do_ocean': '.false.', 'ocean_npes': '0', 'atmos_npes': '48', 'atmos_nthreads': '1', 'use_hyper_thread': '.false.', 'ncores_per_node': '24'}\n",
      "\n",
      "*** vegn_data_nml:{'vegn_to_use': \"'uniform'\", 'K1': '10,', 'K2': '0.1,', 'fsc_liv': '0.9,', 'fsc_wood': '0.45,', 'c1(4)': '0.3', 'c2(4)': '0.3', 'Vmax': '2.0E-5, 2.0E-5, 2.0E-5, 2.0E-5, 1.50E-5,', 'm_cond': '4., 9., 9., 7., 7.,', 'alpha_phot': '0.05, 0.06, 0.06, 0.06, 0.06,', 'gamma_resp': '0.03, 0.02, 0.02, 0.02, 0.02,', 'tc_crit(0:2)': '3*273.16', 'fact_crit_phen(0:4)': '0., 0., 0., 0., 0.', 'fact_crit_fire(0:4)': '0., 0., 0., 0., 0.', 'cnst_crit_phen(0:4)': '0.30, 0.15, 0.15, 0.30, 0.30', 'cnst_crit_fire(0:4)': '0.15,  0.40, 0.15, 0.15, 0.15', 'wet_leaf_dreg(0:4)': '.3, .3, .3, .3, .3', 'ksi': '0, 0, 0, 0, 0,', 'leaf_refl(0:4,1)': '0.11, 0.11, 0.10, 0.10, 0.10', 'leaf_refl(0:4,2)': '0.58, 0.58, 0.45, 0.45, 0.39,', 'dat_root_zeta(0:4)': '0.35212, 0.17039, 0.28909, 0.25813, 0.17039', 'critical_root_density': '0.0,', 'tau_drip_s': '259200.0', 'cmc_lai(0:4)': '0.02, 0.02, 0.02, 0.02, 0.02', 'csc_lai(0:4)': '0.30, 0.30, 0.30, 0.30, 0.60', 'dat_snow_crit': '4*1.e7, .1', 't_transp_min': '268.', 'srl(0:1)': '112.0e3, 150.0e3', 'root_perm': '14*5e-7', 'alpha(1,3)': '4', 'leaf_age_tau(2)': '150', 'smoke_fraction': '0.9, 0.9, 0.6, 0.6, 0.6', 'tg_c3_thresh': '1', 'phen_ev1': '0.2', 'phen_ev2': '0.7', 'cmc_eps': '0.01', 'alpha(0:4,6)': '0.0, 0.0, 0.012, 0.012, 0.012', 'treefall_disturbance_rate': '0.175, 0.185, 0.025, 0.0275, 0.027'}\n",
      "\n",
      "*** simple_sulfate_nml:{'gas_conc_filename': \"'gas_conc_3D_am3p9.nc'\", 'gas_conc_time_dependency_type': \"'constant'\", 'cont_volc_source': \"'do_cont_volc'\", 'expl_volc_source': \"'do_expl_volc'\", 'aerocom_emission_filename': \"'so2_0.25_volcanoes.nc'\", 'aircraft_source': \"'do_aircraft',\", 'aircraft_filename': \"'emissions.aircraft.aero.0.5x0.5.1849-2016.nc',\", 'aircraft_emission_name(1)': \"'fuel'\", 'aircraft_time_dependency_type': \"'time_varying'\", 'aircraft_dataset_entry': '1979 1 1 0 0 0', 'so2_aircraft_EI': '0.001', 'anthro_source': \"'do_anthro',\", 'anthro_emission_name(1)': \"'so2ff',\", 'anthro_emission_name(2)': \"'so4ff',\", 'anthro_time_dependency_type': \"'time_varying'\", 'anthro_dataset_entry': '1979 1 1 0 0 0', 'anthro_filename': \"'anthro_so2.1849_2016.nc',\", 'biobur_source': \"'do_biobur',\", 'biobur_emission_name(1)': \"'so2bb',\", 'biobur_emission_name(2)': \"'so4bb',\", 'biobur_time_dependency_type': \"'time_varying'\", 'biobur_dataset_entry': '1979 1 1 0 0 0', 'biobur_filename': \"'anthro_so2.1849_2016.nc',\", 'cloud_chem_solver': '\"f1p\"', 'pH_cloud': '4.5', 'no_biobur_if_no_pbl': '.false.'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NML_test = NML_from_nml('input_yoder_v101.nml')\n",
    "#\n",
    "\n",
    "# for ky,vl in JJ.nml_dict.items():\n",
    "#     print('** {}: {}'.format(ky,vl))\n",
    "\n",
    "\n",
    "for ky in ['coupler_nml','coupler_nml', 'vegn_data_nml', 'simple_sulfate_nml' ]:\n",
    "    print('*** {}:{}\\n'.format(ky, NML_test[ky]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,35,35,35,35,35,40,40,40,40,40,45,45,45,45,45,50,50,50,50,50,55,55,55,55,55,60,60,60,60,60,65,65,65,65,65,70,70,70,70,70,75,75,75,75,75,80,80,80,80,82,82,84,84,86,86,88,88,90,91,92,93,94,95,96,97,97,97,97,\n"
     ]
    }
   ],
   "source": [
    "print(NML_test['aerosolrad_package_nml']['sulfate_indices'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working NML example.\n",
    "\n",
    "- Start with a standard template\n",
    "- Compute layouts for an MPI configuration\n",
    "- Modify layout variables (in internal JSON/dict)\n",
    "- Export working input.nml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Layouts_1:  [[ 6  8]\n",
      " [ 4 12]\n",
      " [ 3 16]\n",
      " [ 2 24]\n",
      " [ 1 48]]\n",
      "** Layouts_2:  [[2 4]\n",
      " [1 8]]\n",
      "** Layouts_io_1:  [[1 4]\n",
      " [1 8]]\n",
      "** Layouts_io_2:  [[1 4]]\n",
      "** fv_core_nml::layout: 2,4\n",
      "** fv_core_nml::io_layout: 2,4\n",
      "\n",
      "\n",
      "** land_model_nml::layout: 2,4\n",
      "** land_model_nml::io_layout: 2,4\n",
      "\n",
      "\n",
      "** ocean_model_nml::layout: 4,12\n",
      "** ocean_model_nml::io_layout: 4,12\n",
      "\n",
      "\n",
      "** ice_model_nml::layout: 4,12\n",
      "** ice_model_nml::io_layout: 4,12\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "n_tasks = 48\n",
    "n_threads = 1\n",
    "#\n",
    "layouts_1 = get_layouts(n_tasks)\n",
    "layouts_2 = get_layouts(n_tasks = n_tasks/6)\n",
    "#\n",
    "layout_io_1 = get_io_layouts(layouts_1[0])\n",
    "layout_io_2 = get_io_layouts(layouts_2[0])\n",
    "#\n",
    "print('** Layouts_1: ', layouts_1)\n",
    "print('** Layouts_2: ', layouts_2)\n",
    "#\n",
    "print('** Layouts_io_1: ', layout_io_1)\n",
    "print('** Layouts_io_2: ', layout_io_2)\n",
    "#\n",
    "my_nml = NML_from_nml(input_nml='input_yoder_v101.nml')\n",
    "layout_1=layouts_1[0]\n",
    "layout_2=layouts_2[0]\n",
    "#\n",
    "layout_io = layout_io_1[0]\n",
    "\n",
    "#\n",
    "# print out layouts, as they are imported:\n",
    "for grp in ('fv_core_nml', 'land_model_nml','ocean_model_nml', 'ice_model_nml'):\n",
    "    print('** {}::layout: {}'.format(grp, my_nml[grp]['layout']))\n",
    "    print('** {}::io_layout: {}'.format(grp, my_nml[grp]['layout']))\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**  0\n",
      "**  3\n"
     ]
    }
   ],
   "source": [
    "print('** ', 48%6)\n",
    "print('** ', 48%5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** fv_core_nml:: 2,4, 1,4\n",
      "** land_model_nml:: 2,4, 1,4\n",
      "** ocean_model_nml:: 6,8, 1,4\n",
      "** ice_model_nml:: 6,8, 1,4\n",
      "*** radiative_gases:  {'use_co2_10um': '.true.', 'verbose': '3', 'gas_printout_freq': '240', 'time_varying_co2': '.true.', 'co2_variation_type': \"'linear',\", 'co2_dataset_entry': '1979 1 1 0 0 0', 'co2_specification_type': \"'time_series',\", 'co2_floor': 0.0001, 'co2_ceiling': 0.0048, 'co2_data_source': \"'input'\", 'time_varying_ch4': '.true.,', 'ch4_variation_type': \"'linear'\", 'ch4_dataset_entry': '1979 1 1 0 0 0', 'ch4_specification_type': \"'time_series'\", 'ch4_data_source': \"'input'\", 'time_varying_n2o': '.true.,', 'n2o_variation_type': \"'linear'\", 'n2o_dataset_entry': '1979 1 1 0 0 0', 'n2o_specification_type': \"'time_series'\", 'n2o_data_source': \"'input'\", 'time_varying_f11': '.true.,', 'f11_variation_type': \"'linear'\", 'f11_dataset_entry': '1979 1 1 0 0 0', 'f11_specification_type': \"'time_series'\", 'f11_data_source': \"'input'\", 'time_varying_f12': '.true.,', 'f12_variation_type': \"'linear'\", 'f12_dataset_entry': '1979 1 1 0 0 0', 'f12_specification_type': \"'time_series'\", 'f12_data_source': \"'input'\", 'time_varying_f113': '.true.,', 'f113_variation_type': \"'linear'\", 'f113_dataset_entry': '1979 1 1 0 0 0', 'f113_specification_type': \"'time_series'\", 'f113_data_source': \"'input'\", 'time_varying_f22': '.true.,', 'f22_variation_type': \"'linear'\", 'f22_dataset_entry': '1979 1 1 0 0 0', 'f22_specification_type': \"'time_series'\", 'f22_data_source': \"'input'\", 'calc_co2_tfs_on_first_step': '.false.,', 'calc_co2_tfs_monthly': '.true.,', 'co2_tf_time_displacement': '360.0,', 'calc_ch4_tfs_on_first_step': '.false.,', 'calc_ch4_tfs_monthly': '.true.,', 'ch4_tf_time_displacement': '360.0,', 'calc_n2o_tfs_on_first_step': '.false.,', 'calc_n2o_tfs_monthly': '.true.,', 'n2o_tf_time_displacement': '360.0,', 'co2_base_value': 0.000348, 'c02_data_source': 'namelist'}\n"
     ]
    }
   ],
   "source": [
    "#print('** ', my_nml['fv_core_nml']['layout'])\n",
    "#\n",
    "for grp in ('fv_core_nml', 'land_model_nml'):\n",
    "    my_nml.assign(grp, 'layout', ','.join([str(x) for x in layout_2]))\n",
    "    my_nml.assign(grp, 'io_layout', ','.join([str(x) for x in layout_io]))\n",
    "    print('** {}:: {}, {}'.format(grp, my_nml[grp]['layout'], my_nml[grp]['io_layout']))\n",
    "#\n",
    "for grp in ('ocean_model_nml', 'ice_model_nml'):\n",
    "    my_nml.assign(grp, 'layout', ','.join([str(x) for x in layout_1]))\n",
    "    my_nml.assign(grp, 'io_layout', ','.join([str(x) for x in layout_io]))\n",
    "    print('** {}:: {}, {}'.format(grp, my_nml[grp]['layout'], my_nml[grp]['io_layout']))\n",
    "#\n",
    "for ky,vl in [('npx',193), ('npy', 193), ('npz', 50)]:\n",
    "    my_nml.assign('fv_core_nml', ky, vl)\n",
    "#\n",
    "for ky,vl in [('co2_ceiling', 4800.0E-06), ('time_varying_co2', '.true.'), ('co2_base_value',348.0E-06),\n",
    "            ('co2_floor', 100.0E-06), ('c02_data_source', 'namelist') ]:\n",
    "    # NOTE: we want to allow new assignment:\n",
    "    my_nml['radiative_gases_nml'][ky] = vl\n",
    "print('*** radiative_gases: ', my_nml['radiative_gases_nml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** use_co2_10um:: .true.\n",
      "** verbose:: 3\n",
      "** gas_printout_freq:: 240\n",
      "** time_varying_co2:: .true.\n",
      "** co2_variation_type:: 'linear',\n",
      "** co2_dataset_entry:: 1979 1 1 0 0 0\n",
      "** co2_specification_type:: 'time_series',\n",
      "** co2_floor:: 0.0001\n",
      "** co2_ceiling:: 0.0048\n",
      "** co2_data_source:: 'input'\n",
      "** time_varying_ch4:: .true.,\n",
      "** ch4_variation_type:: 'linear'\n",
      "** ch4_dataset_entry:: 1979 1 1 0 0 0\n",
      "** ch4_specification_type:: 'time_series'\n",
      "** ch4_data_source:: 'input'\n",
      "** time_varying_n2o:: .true.,\n",
      "** n2o_variation_type:: 'linear'\n",
      "** n2o_dataset_entry:: 1979 1 1 0 0 0\n",
      "** n2o_specification_type:: 'time_series'\n",
      "** n2o_data_source:: 'input'\n",
      "** time_varying_f11:: .true.,\n",
      "** f11_variation_type:: 'linear'\n",
      "** f11_dataset_entry:: 1979 1 1 0 0 0\n",
      "** f11_specification_type:: 'time_series'\n",
      "** f11_data_source:: 'input'\n",
      "** time_varying_f12:: .true.,\n",
      "** f12_variation_type:: 'linear'\n",
      "** f12_dataset_entry:: 1979 1 1 0 0 0\n",
      "** f12_specification_type:: 'time_series'\n",
      "** f12_data_source:: 'input'\n",
      "** time_varying_f113:: .true.,\n",
      "** f113_variation_type:: 'linear'\n",
      "** f113_dataset_entry:: 1979 1 1 0 0 0\n",
      "** f113_specification_type:: 'time_series'\n",
      "** f113_data_source:: 'input'\n",
      "** time_varying_f22:: .true.,\n",
      "** f22_variation_type:: 'linear'\n",
      "** f22_dataset_entry:: 1979 1 1 0 0 0\n",
      "** f22_specification_type:: 'time_series'\n",
      "** f22_data_source:: 'input'\n",
      "** calc_co2_tfs_on_first_step:: .false.,\n",
      "** calc_co2_tfs_monthly:: .true.,\n",
      "** co2_tf_time_displacement:: 360.0,\n",
      "** calc_ch4_tfs_on_first_step:: .false.,\n",
      "** calc_ch4_tfs_monthly:: .true.,\n",
      "** ch4_tf_time_displacement:: 360.0,\n",
      "** calc_n2o_tfs_on_first_step:: .false.,\n",
      "** calc_n2o_tfs_monthly:: .true.,\n",
      "** n2o_tf_time_displacement:: 360.0,\n",
      "** co2_base_value:: 0.000348\n",
      "** c02_data_source:: namelist\n",
      "\n",
      "\n",
      "\n",
      "** layout:: 2,4\n",
      "** io_layout:: 1,4\n",
      "** npx:: 193\n",
      "** npy:: 193\n",
      "** ntiles:: 6,\n",
      "** npz:: 50\n",
      "** k_split:: 1,\n",
      "** n_split:: 12,\n",
      "** a2b_ord:: 4,\n",
      "** adjust_dry_mass:: .true.,\n",
      "** adj_mass_vmr:: .true.,\n",
      "** print_freq:: 0,\n",
      "** grid_type:: 0,\n",
      "** tau:: 0.\n",
      "** do_uni_zfull:: .true.\n",
      "** n_sponge:: 0\n",
      "** d2_bg_k1:: 0.16\n",
      "** d2_bg_k2:: 0.02\n",
      "** kord_tm:: -10\n",
      "** kord_mt:: 10\n",
      "** kord_tr:: 10\n",
      "** hydrostatic:: .T.\n",
      "** d_ext:: 0.\n",
      "** d2_bg:: 0.\n",
      "** nord:: 2\n",
      "** dddmp:: 0.\n",
      "** d4_bg:: 0.15\n",
      "** vtdm4:: 0.0\n",
      "** do_vort_damp:: .F.\n",
      "** d_con:: 0.\n",
      "** hord_mt:: 10\n",
      "** hord_vt:: 10\n",
      "** hord_tm:: 10\n",
      "** hord_dp:: 10\n",
      "** hord_tr:: 8\n",
      "** consv_te:: 0.7\n",
      "** consv_am:: .T.\n",
      "** fill:: .T.\n",
      "** z_tracer:: .T.\n"
     ]
    }
   ],
   "source": [
    "for ky,vl in my_nml['radiative_gases_nml'].items():\n",
    "    print('** {}:: {}'.format(ky, vl))\n",
    "print('\\n\\n')\n",
    "#\n",
    "for ky,vl in my_nml['fv_core_nml'].items():\n",
    "    print('** {}:: {}'.format(ky, vl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_nml.json_to_nml(nml_out='my_output.nml', json_in=my_nml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2,3\n"
     ]
    }
   ],
   "source": [
    "print(','.join([str(x) for x in [1,2,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
